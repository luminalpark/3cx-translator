<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Streaming Translation Test</title>
    <style>
        * { box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background: #1a1a2e;
            color: #eee;
        }
        h1 { color: #00d4ff; margin-bottom: 5px; }
        .subtitle { color: #888; margin-bottom: 20px; }
        .panel {
            background: #16213e;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
        }
        .status {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
        }
        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #666;
        }
        .status-dot.connected { background: #00ff88; }
        .status-dot.streaming { background: #ffd700; animation: pulse 0.5s infinite; }
        .status-dot.speaking { background: #ff6b6b; animation: pulse 0.3s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }

        button {
            background: #00d4ff;
            color: #000;
            border: none;
            padding: 12px 24px;
            border-radius: 6px;
            font-size: 16px;
            cursor: pointer;
            margin-right: 10px;
            margin-bottom: 10px;
        }
        button:hover { background: #00b8e6; }
        button:disabled { background: #444; color: #888; cursor: not-allowed; }
        button.stop { background: #ff6b6b; }
        button.stop:hover { background: #ff5252; }

        .config {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr 1fr;
            gap: 15px;
            margin-bottom: 15px;
        }
        label { display: block; margin-bottom: 5px; color: #aaa; }
        select, input {
            width: 100%;
            padding: 10px;
            border-radius: 6px;
            border: 1px solid #333;
            background: #0f0f23;
            color: #fff;
            font-size: 14px;
        }

        .mode-badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: bold;
            margin-left: 10px;
            background: #00ff88;
            color: #000;
        }

        .log {
            background: #0f0f23;
            border-radius: 6px;
            padding: 15px;
            height: 250px;
            overflow-y: auto;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 13px;
            line-height: 1.5;
        }
        .log-entry { margin-bottom: 5px; }
        .log-entry.event { color: #00d4ff; }
        .log-entry.source { color: #ffd700; }
        .log-entry.translation { color: #00ff88; }
        .log-entry.error { color: #ff6b6b; }
        .log-entry.audio { color: #888; }

        .translation-display {
            background: #0f0f23;
            border-radius: 6px;
            padding: 20px;
            min-height: 100px;
        }
        .translation-display .source {
            color: #ffd700;
            font-size: 18px;
            margin-bottom: 10px;
        }
        .translation-display .translated {
            color: #00ff88;
            font-size: 20px;
            font-weight: bold;
        }
        .translation-display .placeholder {
            color: #666;
            font-style: italic;
        }
        .streaming-indicator {
            display: none;
            color: #ffd700;
            font-size: 12px;
            margin-top: 10px;
            animation: blink 1s infinite;
        }
        @keyframes blink { 0%, 100% { opacity: 1; } 50% { opacity: 0.3; } }

        .mute-indicator {
            display: none;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: bold;
            margin-left: 10px;
            background: #ff6b6b;
            color: #fff;
            animation: pulse 0.5s infinite;
        }

        /* VAD Settings Panel */
        .vad-panel {
            margin-top: 15px;
            border-top: 1px solid #333;
            padding-top: 15px;
        }
        .vad-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            cursor: pointer;
            user-select: none;
        }
        .vad-header h4 {
            margin: 0;
            color: #00d4ff;
            font-size: 14px;
        }
        .vad-toggle {
            color: #888;
            font-size: 12px;
        }
        .vad-content {
            display: none;
            margin-top: 15px;
        }
        .vad-content.expanded { display: block; }
        .vad-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
        }
        .vad-item {
            background: #0f0f23;
            border-radius: 6px;
            padding: 12px;
        }
        .vad-item label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 8px;
            font-size: 12px;
        }
        .vad-item label span.value {
            color: #00d4ff;
            font-weight: bold;
        }
        .vad-item input[type="range"] {
            width: 100%;
            -webkit-appearance: none;
            height: 6px;
            border-radius: 3px;
            background: #333;
            cursor: pointer;
        }
        .vad-item input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: #00d4ff;
            cursor: pointer;
        }
        .vad-item input[type="range"]::-moz-range-thumb {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: #00d4ff;
            cursor: pointer;
            border: none;
        }
        .vad-item .hint {
            font-size: 10px;
            color: #666;
            margin-top: 5px;
        }
        .vad-presets {
            margin-top: 15px;
            display: flex;
            gap: 10px;
        }
        .vad-presets button {
            padding: 8px 16px;
            font-size: 12px;
            background: #333;
            color: #aaa;
        }
        .vad-presets button:hover {
            background: #444;
            color: #fff;
        }
        .rms-meter {
            margin-top: 15px;
            background: #0f0f23;
            border-radius: 6px;
            padding: 12px;
        }
        .rms-bar-container {
            height: 20px;
            background: #333;
            border-radius: 4px;
            overflow: hidden;
            position: relative;
        }
        .rms-bar {
            height: 100%;
            background: linear-gradient(to right, #00ff88, #ffd700, #ff6b6b);
            width: 0%;
            transition: width 0.05s;
        }
        .rms-markers {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            pointer-events: none;
        }
        .rms-marker {
            position: absolute;
            top: 0;
            bottom: 0;
            width: 2px;
            background: rgba(255,255,255,0.5);
        }
        .rms-value {
            font-size: 12px;
            color: #888;
            margin-top: 5px;
            display: flex;
            justify-content: space-between;
        }
    </style>
</head>
<body>
    <h1>Gemini Streaming Translation</h1>
    <p class="subtitle">Real-time translation with persistent Gemini Live session</p>

    <div class="panel">
        <div class="status">
            <div class="status-dot" id="statusDot"></div>
            <span id="statusText">Disconnected</span>
            <span class="mode-badge" id="modeBadge" style="display: none;">STREAMING</span>
            <span class="mute-indicator" id="muteIndicator">MIC MUTED</span>
        </div>

        <div class="config">
            <div>
                <label>Server URL</label>
                <input type="text" id="serverUrl" value="ws://localhost:8001/ws/translate">
            </div>
            <div>
                <label>API Key (optional)</label>
                <input type="password" id="apiKey" placeholder="Leave empty if not required">
            </div>
            <div>
                <label>Target Language</label>
                <select id="targetLang">
                    <option value="it">Italian</option>
                    <option value="en">English</option>
                    <option value="de">German</option>
                    <option value="es">Spanish</option>
                    <option value="fr">French</option>
                </select>
            </div>
            <div>
                <label>Gemini Voice</label>
                <select id="geminiVoice">
                    <option value="Kore">Kore (Female)</option>
                    <option value="Aoede">Aoede (Female)</option>
                    <option value="Charon">Charon (Male)</option>
                    <option value="Fenrir">Fenrir (Male)</option>
                    <option value="Puck">Puck (Male)</option>
                </select>
            </div>
        </div>

        <button id="startBtn" onclick="start()">Start Streaming</button>
        <button id="endTurnBtn" onclick="endTurn()" disabled style="display: none;">End Turn (Manual)</button>
        <button id="stopBtn" onclick="stop()" disabled class="stop">Stop</button>

        <!-- VAD Settings Panel -->
        <div class="vad-panel">
            <div class="vad-header" onclick="toggleVadPanel()">
                <h4>‚öôÔ∏è VAD Settings (Voice Activity Detection)</h4>
                <span class="vad-toggle" id="vadToggle">‚ñ∂ Expand</span>
            </div>
            <div class="vad-content" id="vadContent">
                <!-- RMS Meter -->
                <div class="rms-meter">
                    <label style="margin-bottom: 8px;">Live RMS Level</label>
                    <div class="rms-bar-container">
                        <div class="rms-bar" id="rmsBar"></div>
                        <div class="rms-markers" id="rmsMarkers"></div>
                    </div>
                    <div class="rms-value">
                        <span id="rmsValueText">RMS: 0.0000</span>
                        <span id="turnStateText">State: IDLE</span>
                    </div>
                </div>

                <div class="vad-grid">
                    <!-- Speech Threshold -->
                    <div class="vad-item">
                        <label>
                            <span>Speech Threshold</span>
                            <span class="value" id="speechThresholdValue">0.012</span>
                        </label>
                        <input type="range" id="speechThreshold" min="0.001" max="0.05" step="0.001" value="0.012"
                               oninput="updateVadParam('speechThreshold', this.value)">
                        <div class="hint">RMS level to start a turn (green marker)</div>
                    </div>

                    <!-- Silence Threshold -->
                    <div class="vad-item">
                        <label>
                            <span>Silence Threshold</span>
                            <span class="value" id="silenceThresholdValue">0.006</span>
                        </label>
                        <input type="range" id="silenceThreshold" min="0.001" max="0.03" step="0.001" value="0.006"
                               oninput="updateVadParam('silenceThreshold', this.value)">
                        <div class="hint">RMS level considered silence (red marker)</div>
                    </div>

                    <!-- Auto-Restart Threshold -->
                    <div class="vad-item">
                        <label>
                            <span>Auto-Restart Threshold</span>
                            <span class="value" id="autoRestartThresholdValue">0.009</span>
                        </label>
                        <input type="range" id="autoRestartThreshold" min="0.001" max="0.03" step="0.001" value="0.009"
                               oninput="updateVadParam('autoRestartThreshold', this.value)">
                        <div class="hint">RMS level to auto-restart after turn_complete (yellow marker)</div>
                    </div>

                    <!-- Silence Duration -->
                    <div class="vad-item">
                        <label>
                            <span>Silence Duration (ms)</span>
                            <span class="value" id="silenceDurationValue">350</span>
                        </label>
                        <input type="range" id="silenceDuration" min="100" max="1000" step="50" value="350"
                               oninput="updateVadParam('silenceDuration', this.value)">
                        <div class="hint">Silence duration to trigger activity_end</div>
                    </div>

                    <!-- Min Turn Duration -->
                    <div class="vad-item">
                        <label>
                            <span>Min Turn Duration (ms)</span>
                            <span class="value" id="minTurnDurationValue">900</span>
                        </label>
                        <input type="range" id="minTurnDuration" min="300" max="2000" step="100" value="900"
                               oninput="updateVadParam('minTurnDuration', this.value)">
                        <div class="hint">Minimum turn length before allowing closure</div>
                    </div>

                    <!-- Max Turn Duration -->
                    <div class="vad-item">
                        <label>
                            <span>Max Turn Duration (ms)</span>
                            <span class="value" id="maxTurnDurationValue">5000</span>
                        </label>
                        <input type="range" id="maxTurnDuration" min="2000" max="15000" step="500" value="5000"
                               oninput="updateVadParam('maxTurnDuration', this.value)">
                        <div class="hint">Safety limit - closes only if also near-silence</div>
                    </div>

                    <!-- Overlap Duration -->
                    <div class="vad-item">
                        <label>
                            <span>Overlap Duration (ms)</span>
                            <span class="value" id="overlapDurationValue">250</span>
                        </label>
                        <input type="range" id="overlapDuration" min="0" max="500" step="50" value="250"
                               oninput="updateVadParam('overlapDuration', this.value)">
                        <div class="hint">Audio carried between turns for continuity</div>
                    </div>

                    <!-- Pending Buffer Max -->
                    <div class="vad-item">
                        <label>
                            <span>Pending Buffer (KB)</span>
                            <span class="value" id="pendingBufferValue">64</span>
                        </label>
                        <input type="range" id="pendingBuffer" min="16" max="128" step="8" value="64"
                               oninput="updateVadParam('pendingBuffer', this.value)">
                        <div class="hint">Max buffer during WAIT_COMPLETE (~2s = 64KB)</div>
                    </div>
                </div>

                <!-- Presets -->
                <div class="vad-presets">
                    <button onclick="applyPreset('voip')">üìû VoIP/Telephony</button>
                    <button onclick="applyPreset('quiet')">ü§´ Quiet Environment</button>
                    <button onclick="applyPreset('noisy')">üîä Noisy Environment</button>
                    <button onclick="applyPreset('fast')">‚ö° Fast Response</button>
                </div>
            </div>
        </div>
    </div>

    <div class="panel">
        <h3>Live Translation</h3>
        <div class="translation-display">
            <div class="source" id="sourceText"></div>
            <div class="translated" id="translatedText"></div>
            <div class="placeholder" id="placeholder">Speak into your microphone...</div>
            <div class="streaming-indicator" id="streamingIndicator">Listening and translating in real-time...</div>
        </div>
    </div>

    <div class="panel">
        <h3>Event Log</h3>
        <div class="log" id="log"></div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let isRecording = false;
        let audioQueue = [];
        let isPlaying = false;
        let isMuted = false;  // Mute mic during audio playback
        let unmuteTimeout = null;

        // Manual VAD State Machine
        // IDLE: waiting for speech, not sending audio to server
        // ACTIVE: speech detected, sent activity_start, sending audio chunks
        // WAIT_COMPLETE: sent activity_end, waiting for turn_complete, NOT sending audio
        let turnState = 'IDLE';

        // VAD settings (ottimizzate per VoIP/telefonia) - now editable!
        let VAD_SPEECH_THRESHOLD = 0.012;   // RMS threshold to detect speech start (lower for VoIP)
        let VAD_SILENCE_THRESHOLD = 0.006;  // RMS threshold for silence (lower for telephony)
        let VAD_SILENCE_DURATION_MS = 350;  // Trigger translation after 350ms silence
        let MIN_TURN_DURATION_MS = 900;     // Don't close turn if less than 900ms of speech
        let MAX_TURN_MS = 5000;             // Safety limit at 5s, NOT a fixed timer
        let AUTO_RESTART_THRESHOLD = 0.009; // RMS threshold for auto-restart (coerente con speech)

        // Buffer e Overlap settings - now editable!
        let OVERLAP_MS = 250;
        let OVERLAP_BYTES = Math.floor(16000 * (OVERLAP_MS / 1000)) * 2; // Recalculated when OVERLAP_MS changes
        let PENDING_MAX_BYTES = 64 * 1024; // ~2s di PCM16 mono @16kHz = 64KB

        let silenceStartTime = null;
        let speechStartTime = null;           // When the current turn started
        let sampleRateLogged = false;         // Log sample rate once
        let lastRms = 0;                      // Store last RMS for auto-restart in handleMessage
        let overlapTail = null;               // Last 250ms of audio for overlap
        let pendingAudioChunks = [];          // Buffer audio during WAIT_COMPLETE
        let pendingBytes = 0;                 // Track pending buffer size

        function setTurnState(newState) {
            const oldState = turnState;
            turnState = newState;
            log(`Turn state: ${oldState} ‚Üí ${newState}`, 'event');
            // Update UI
            const turnStateText = document.getElementById('turnStateText');
            if (turnStateText) {
                turnStateText.textContent = `State: ${newState}`;
                turnStateText.style.color = newState === 'ACTIVE' ? '#00ff88' :
                                            newState === 'WAIT_COMPLETE' ? '#ffd700' : '#888';
            }
        }

        // ============================================================
        // VAD Settings Panel Functions
        // ============================================================

        function toggleVadPanel() {
            const content = document.getElementById('vadContent');
            const toggle = document.getElementById('vadToggle');
            const isExpanded = content.classList.toggle('expanded');
            toggle.textContent = isExpanded ? '‚ñº Collapse' : '‚ñ∂ Expand';
            if (isExpanded) {
                updateRmsMarkers();
            }
        }

        function updateVadParam(param, value) {
            const numValue = parseFloat(value);

            switch(param) {
                case 'speechThreshold':
                    VAD_SPEECH_THRESHOLD = numValue;
                    document.getElementById('speechThresholdValue').textContent = numValue.toFixed(3);
                    break;
                case 'silenceThreshold':
                    VAD_SILENCE_THRESHOLD = numValue;
                    document.getElementById('silenceThresholdValue').textContent = numValue.toFixed(3);
                    break;
                case 'autoRestartThreshold':
                    AUTO_RESTART_THRESHOLD = numValue;
                    document.getElementById('autoRestartThresholdValue').textContent = numValue.toFixed(3);
                    break;
                case 'silenceDuration':
                    VAD_SILENCE_DURATION_MS = parseInt(value);
                    document.getElementById('silenceDurationValue').textContent = value;
                    break;
                case 'minTurnDuration':
                    MIN_TURN_DURATION_MS = parseInt(value);
                    document.getElementById('minTurnDurationValue').textContent = value;
                    break;
                case 'maxTurnDuration':
                    MAX_TURN_MS = parseInt(value);
                    document.getElementById('maxTurnDurationValue').textContent = value;
                    break;
                case 'overlapDuration':
                    OVERLAP_MS = parseInt(value);
                    OVERLAP_BYTES = Math.floor(16000 * (OVERLAP_MS / 1000)) * 2;
                    document.getElementById('overlapDurationValue').textContent = value;
                    break;
                case 'pendingBuffer':
                    PENDING_MAX_BYTES = parseInt(value) * 1024;
                    document.getElementById('pendingBufferValue').textContent = value;
                    break;
            }

            updateRmsMarkers();
            log(`VAD param updated: ${param} = ${value}`, 'event');
        }

        function updateRmsMarkers() {
            const markersContainer = document.getElementById('rmsMarkers');
            if (!markersContainer) return;

            // Scale: 0 to 0.1 RMS = 0% to 100%
            const scale = 1000; // 0.1 RMS = 100%

            markersContainer.innerHTML = `
                <div class="rms-marker" style="left: ${VAD_SILENCE_THRESHOLD * scale}%; background: #ff6b6b;" title="Silence: ${VAD_SILENCE_THRESHOLD}"></div>
                <div class="rms-marker" style="left: ${AUTO_RESTART_THRESHOLD * scale}%; background: #ffd700;" title="Auto-restart: ${AUTO_RESTART_THRESHOLD}"></div>
                <div class="rms-marker" style="left: ${VAD_SPEECH_THRESHOLD * scale}%; background: #00ff88;" title="Speech: ${VAD_SPEECH_THRESHOLD}"></div>
            `;
        }

        function updateRmsMeter(rms) {
            const rmsBar = document.getElementById('rmsBar');
            const rmsValueText = document.getElementById('rmsValueText');
            if (!rmsBar || !rmsValueText) return;

            // Scale: 0 to 0.1 RMS = 0% to 100%
            const percentage = Math.min(100, rms * 1000);
            rmsBar.style.width = percentage + '%';
            rmsValueText.textContent = `RMS: ${rms.toFixed(4)}`;
        }

        function applyPreset(preset) {
            const presets = {
                voip: {
                    speechThreshold: 0.012,
                    silenceThreshold: 0.006,
                    autoRestartThreshold: 0.009,
                    silenceDuration: 350,
                    minTurnDuration: 900,
                    maxTurnDuration: 5000,
                    overlapDuration: 250,
                    pendingBuffer: 64
                },
                quiet: {
                    speechThreshold: 0.008,
                    silenceThreshold: 0.003,
                    autoRestartThreshold: 0.005,
                    silenceDuration: 400,
                    minTurnDuration: 800,
                    maxTurnDuration: 6000,
                    overlapDuration: 300,
                    pendingBuffer: 64
                },
                noisy: {
                    speechThreshold: 0.025,
                    silenceThreshold: 0.015,
                    autoRestartThreshold: 0.020,
                    silenceDuration: 300,
                    minTurnDuration: 1000,
                    maxTurnDuration: 4000,
                    overlapDuration: 200,
                    pendingBuffer: 64
                },
                fast: {
                    speechThreshold: 0.015,
                    silenceThreshold: 0.008,
                    autoRestartThreshold: 0.012,
                    silenceDuration: 250,
                    minTurnDuration: 600,
                    maxTurnDuration: 3000,
                    overlapDuration: 150,
                    pendingBuffer: 48
                }
            };

            const p = presets[preset];
            if (!p) return;

            // Update sliders and values
            document.getElementById('speechThreshold').value = p.speechThreshold;
            document.getElementById('silenceThreshold').value = p.silenceThreshold;
            document.getElementById('autoRestartThreshold').value = p.autoRestartThreshold;
            document.getElementById('silenceDuration').value = p.silenceDuration;
            document.getElementById('minTurnDuration').value = p.minTurnDuration;
            document.getElementById('maxTurnDuration').value = p.maxTurnDuration;
            document.getElementById('overlapDuration').value = p.overlapDuration;
            document.getElementById('pendingBuffer').value = p.pendingBuffer;

            // Apply all values
            updateVadParam('speechThreshold', p.speechThreshold);
            updateVadParam('silenceThreshold', p.silenceThreshold);
            updateVadParam('autoRestartThreshold', p.autoRestartThreshold);
            updateVadParam('silenceDuration', p.silenceDuration);
            updateVadParam('minTurnDuration', p.minTurnDuration);
            updateVadParam('maxTurnDuration', p.maxTurnDuration);
            updateVadParam('overlapDuration', p.overlapDuration);
            updateVadParam('pendingBuffer', p.pendingBuffer);

            log(`Applied VAD preset: ${preset}`, 'event');
        }

        // Initialize markers on page load
        document.addEventListener('DOMContentLoaded', updateRmsMarkers);

        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        const startBtn = document.getElementById('startBtn');
        const endTurnBtn = document.getElementById('endTurnBtn');
        const stopBtn = document.getElementById('stopBtn');
        const logDiv = document.getElementById('log');
        const sourceText = document.getElementById('sourceText');
        const translatedText = document.getElementById('translatedText');
        const placeholder = document.getElementById('placeholder');
        const modeBadge = document.getElementById('modeBadge');
        const streamingIndicator = document.getElementById('streamingIndicator');
        const muteIndicator = document.getElementById('muteIndicator');

        function log(message, type = '') {
            const entry = document.createElement('div');
            entry.className = 'log-entry ' + type;
            entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            logDiv.appendChild(entry);
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        // Normalize BCP-47 language codes to simple 2-letter codes
        // Gemini doesn't accept extended codes like 'es-ES', only 'es'
        function normalizeLanguageCode(code) {
            if (!code || code === 'auto') return code;
            return code.split('-')[0].split('_')[0].toLowerCase();
        }

        function setStatus(status, state = 'idle') {
            statusText.textContent = status;
            statusDot.className = 'status-dot';
            if (status.includes('Connected')) statusDot.classList.add('connected');
            if (state === 'streaming') statusDot.classList.add('streaming');
            if (state === 'speaking') statusDot.classList.add('speaking');
        }

        async function start() {
            try {
                // Get microphone access
                log('Requesting microphone access...');
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                // Create audio context
                audioContext = new AudioContext({ sampleRate: 16000 });

                // Connect to WebSocket
                let serverUrl = document.getElementById('serverUrl').value;
                const apiKey = document.getElementById('apiKey').value;

                // Add API key if provided
                if (apiKey) {
                    const separator = serverUrl.includes('?') ? '&' : '?';
                    serverUrl = `${serverUrl}${separator}key=${encodeURIComponent(apiKey)}`;
                    log(`Connecting to ${document.getElementById('serverUrl').value} (with API key)...`);
                } else {
                    log(`Connecting to ${serverUrl}...`);
                }

                ws = new WebSocket(serverUrl);
                ws.binaryType = 'arraybuffer';

                ws.onopen = () => {
                    log('WebSocket connected', 'event');
                    setStatus('Connected - Configuring...');
                };

                ws.onmessage = async (event) => {
                    if (event.data instanceof ArrayBuffer) {
                        // Audio data as ArrayBuffer - queue for playback
                        const audioData = new Int16Array(event.data);
                        log(`Received ${audioData.length} audio samples (ArrayBuffer)`, 'audio');
                        queueAudioPlayback(audioData);
                    } else if (event.data instanceof Blob) {
                        // Audio data as Blob - convert to ArrayBuffer first
                        const arrayBuffer = await event.data.arrayBuffer();
                        const audioData = new Int16Array(arrayBuffer);
                        log(`Received ${audioData.length} audio samples (Blob)`, 'audio');
                        queueAudioPlayback(audioData);
                    } else if (typeof event.data === 'string') {
                        // JSON message
                        const data = JSON.parse(event.data);
                        handleMessage(data);
                    } else {
                        log(`Unknown message type: ${typeof event.data}`, 'error');
                    }
                };

                ws.onclose = () => {
                    log('WebSocket disconnected', 'error');
                    setStatus('Disconnected');
                    stopRecording();
                    modeBadge.style.display = 'none';
                    streamingIndicator.style.display = 'none';
                    endTurnBtn.disabled = true;
                };

                ws.onerror = (err) => {
                    log('WebSocket error: ' + err.message, 'error');
                };

                startBtn.disabled = true;
                endTurnBtn.disabled = false;
                stopBtn.disabled = false;

            } catch (err) {
                log('Error: ' + err.message, 'error');
                console.error(err);
            }
        }

        function endTurn() {
            if (ws && ws.readyState === WebSocket.OPEN && turnState === 'ACTIVE') {
                const turnDuration = speechStartTime ? Date.now() - speechStartTime : 0;
                log(`Manual: Sending activity_end (turn ${turnDuration}ms)...`, 'event');
                ws.send(JSON.stringify({ type: 'activity_end' }));
                setTurnState('WAIT_COMPLETE');
                silenceStartTime = null;
                speechStartTime = null;
            }
        }

        function handleMessage(data) {
            switch (data.type) {
                case 'connected':
                    log(`Server: ${data.server}, Model: ${data.model}`, 'event');
                    log(`Voice: ${data.voice}, Streaming: ${data.streaming_supported}`, 'event');
                    setStatus('Connected - Configuring...');

                    // Configure language (normalize codes for Gemini compatibility)
                    const targetLang = normalizeLanguageCode(document.getElementById('targetLang').value);
                    ws.send(JSON.stringify({
                        type: 'configure',
                        source_lang: 'auto',
                        target_lang: targetLang
                    }));
                    break;

                case 'configured':
                    log(`Language: ${data.source_lang} -> ${data.target_lang}`, 'event');

                    // Enable streaming mode
                    ws.send(JSON.stringify({ type: 'set_streaming', enabled: true }));
                    break;

                case 'streaming_enabled':
                    if (data.enabled) {
                        log('Streaming mode enabled - Manual VAD with client-side silence detection', 'event');
                        setStatus('Connected - Streaming', 'streaming');
                        modeBadge.style.display = 'inline-block';
                        streamingIndicator.style.display = 'block';
                        placeholder.style.display = 'none';
                        // Reset state machine
                        turnState = 'IDLE';
                        silenceStartTime = null;
                        speechStartTime = null;
                        sampleRateLogged = false;
                        // Show manual End Turn button
                        endTurnBtn.style.display = 'inline-block';
                        endTurnBtn.disabled = false;
                        // Start recording
                        startRecording();
                    } else {
                        log('Streaming mode disabled', 'event');
                        modeBadge.style.display = 'none';
                        streamingIndicator.style.display = 'none';
                        endTurnBtn.style.display = 'none';
                    }
                    break;

                case 'streaming_session_ready':
                    log(`Streaming session ready: ${data.source_lang} -> ${data.target_lang}`, 'event');
                    break;

                case 'source_text':
                    // Streaming source text (incremental)
                    if (data.text) {
                        sourceText.textContent = data.text;
                        log(`Source: "${data.text}"`, 'source');
                        setStatus('Connected - Speaking...', 'speaking');
                    }
                    break;

                case 'translated_text':
                    // Streaming translated text (incremental)
                    if (data.text) {
                        translatedText.textContent = data.text;
                        log(`Translation: "${data.text}"`, 'translation');
                    }
                    break;

                case 'model_text':
                    // TEXT response from model (for debugging when AUDIO+TEXT modalities enabled)
                    if (data.text) {
                        log(`Model TEXT: "${data.text}"`, 'translation');
                    }
                    break;

                case 'model_turn_started':
                    log('Gemini speaking (your audio is buffered)', 'event');
                    setStatus('Connected - Translating...', 'speaking');
                    break;

                case 'turn_complete':
                    log('Turn complete - checking for auto-restart', 'event');
                    setStatus('Connected - Streaming', 'streaming');

                    if (lastRms > AUTO_RESTART_THRESHOLD) {
                        log(`Auto-restart (RMS: ${lastRms.toFixed(4)}) - sending activity_start`, 'event');
                        ws.send(JSON.stringify({ type: 'activity_start' }));

                        // Invia overlap per continuit√† lessicale
                        if (overlapTail) {
                            log(`Sending overlap: ${overlapTail.byteLength} bytes`, 'audio');
                            ws.send(overlapTail);
                            overlapTail = null;
                        }

                        // Flush pending audio (bufferizzato durante WAIT_COMPLETE)
                        if (pendingAudioChunks.length) {
                            log(`Flushing buffered audio: ${pendingAudioChunks.length} chunks (${pendingBytes} bytes)`, 'event');
                            for (const buf of pendingAudioChunks) {
                                ws.send(buf);
                            }
                            pendingAudioChunks = [];
                            pendingBytes = 0;
                        }

                        setTurnState('ACTIVE');
                        speechStartTime = Date.now();
                        silenceStartTime = null;
                    } else {
                        // No speech detected - go to IDLE and wait for next speech
                        setTurnState('IDLE');
                        silenceStartTime = null;
                        speechStartTime = null;
                        // Svuota buffer se nessuno parla
                        pendingAudioChunks = [];
                        pendingBytes = 0;
                    }
                    break;

                case 'end_of_turn_sent':
                    log('End of turn acknowledged - waiting for translation', 'event');
                    break;

                case 'activity_start_sent':
                    log('Activity start acknowledged - listening...', 'event');
                    break;

                case 'activity_end_sent':
                    log('Activity end acknowledged - translating...', 'event');
                    break;

                case 'translation':
                    // Full translation (buffer mode)
                    log(`Source: "${data.source_text}"`, 'source');
                    log(`Translation: "${data.translated_text}"`, 'translation');
                    sourceText.textContent = data.source_text;
                    translatedText.textContent = data.translated_text;
                    break;

                case 'error':
                    log(`Error: ${data.message}`, 'error');
                    break;

                default:
                    log(`Event: ${data.type}`, 'event');
            }
        }

        function startRecording() {
            if (isRecording) return;

            const source = audioContext.createMediaStreamSource(mediaStream);

            // Use ScriptProcessorNode for audio capture
            processor = audioContext.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = (e) => {
                if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;

                // Skip sending audio when muted (during playback)
                if (isMuted) return;

                const inputData = e.inputBuffer.getChannelData(0);

                // Log sample rate once for debugging
                if (!sampleRateLogged) {
                    log(`Input buffer sampleRate: ${e.inputBuffer.sampleRate}`, 'event');
                    log(`AudioContext sampleRate: ${audioContext.sampleRate}`, 'event');
                    sampleRateLogged = true;
                }

                // Calculate RMS energy for voice activity detection
                let sum = 0;
                for (let i = 0; i < inputData.length; i++) {
                    sum += inputData[i] * inputData[i];
                }
                const rms = Math.sqrt(sum / inputData.length);
                lastRms = rms;  // Store for auto-restart check in handleMessage
                updateRmsMeter(rms);  // Update live RMS display

                const now = Date.now();

                // STATE MACHINE LOGIC
                if (turnState === 'IDLE') {
                    // Waiting for speech - check if speech starts
                    if (rms > VAD_SPEECH_THRESHOLD) {
                        // Speech detected! Send activity_start and transition to ACTIVE
                        log(`Speech detected (RMS: ${rms.toFixed(4)}) - sending activity_start`, 'event');
                        ws.send(JSON.stringify({ type: 'activity_start' }));

                        // Invia overlap per continuit√† lessicale (dal turno precedente)
                        if (overlapTail) {
                            log(`Sending overlap: ${overlapTail.byteLength} bytes`, 'audio');
                            ws.send(overlapTail);
                            overlapTail = null;
                        }

                        setTurnState('ACTIVE');
                        speechStartTime = now;  // Track when this turn started
                        silenceStartTime = null;
                        // DON'T return - continue to send this first chunk!
                    } else {
                        // In IDLE state with no speech, do NOT send audio chunks
                        return;
                    }
                }

                if (turnState === 'ACTIVE') {
                    const turnDuration = now - speechStartTime;

                    // MAX_TURN come SAFETY: chiudi solo se near-silence
                    // NON troncare in piena sillaba!
                    if (turnDuration >= MAX_TURN_MS && rms < VAD_SILENCE_THRESHOLD) {
                        log(`Max turn ${turnDuration}ms near-silence - sending activity_end`, 'event');
                        ws.send(JSON.stringify({ type: 'activity_end' }));
                        setTurnState('WAIT_COMPLETE');
                        silenceStartTime = null;
                        return;
                    }

                    // Chiusura preferita: su silenzio vero (350ms)
                    if (rms > VAD_SILENCE_THRESHOLD) {
                        // Still speaking - reset silence timer
                        silenceStartTime = null;
                    } else {
                        // Silence detected - start timer if not already started
                        if (!silenceStartTime) {
                            silenceStartTime = now;
                        }

                        // Check if silence duration exceeded threshold
                        const silenceDuration = now - silenceStartTime;

                        // Close turn on natural pauses
                        if (silenceDuration >= VAD_SILENCE_DURATION_MS && turnDuration >= MIN_TURN_DURATION_MS) {
                            log(`Silence ${silenceDuration}ms (turn ${turnDuration}ms) - sending activity_end`, 'event');
                            ws.send(JSON.stringify({ type: 'activity_end' }));
                            setTurnState('WAIT_COMPLETE');
                            silenceStartTime = null;
                            return;
                        }
                    }

                    // Convert Float32 to Int16 and send audio
                    const int16Data = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Salva tail per overlap (ultimi 250ms per continuit√† lessicale)
                    const bytes = new Uint8Array(int16Data.buffer);
                    if (bytes.byteLength >= OVERLAP_BYTES) {
                        overlapTail = bytes.slice(bytes.byteLength - OVERLAP_BYTES).buffer;
                    } else {
                        overlapTail = int16Data.buffer;
                    }

                    ws.send(int16Data.buffer);
                    return;
                }

                if (turnState === 'WAIT_COMPLETE') {
                    // NON droppare! Continua a calcolare RMS e BUFFERIZZA audio
                    // lastRms √® gi√† aggiornato sopra, quindi auto-restart user√† RMS corrente

                    // Converti e bufferizza
                    const int16Data = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Limita la memoria: tieni solo gli ultimi ~2s
                    pendingAudioChunks.push(int16Data.buffer);
                    pendingBytes += int16Data.byteLength;
                    while (pendingBytes > PENDING_MAX_BYTES) {
                        const removed = pendingAudioChunks.shift();
                        pendingBytes -= removed.byteLength;
                    }
                    return;
                }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);

            isRecording = true;
            log('Recording started - speak into your microphone', 'event');
        }

        function stopRecording() {
            isRecording = false;
            if (processor) {
                processor.disconnect();
                processor = null;
            }
        }

        function queueAudioPlayback(int16Data) {
            // Full duplex mode: don't mute microphone during playback
            // Echo cancellation should handle feedback
            // This allows speaking while translation is playing
            log(`Queueing ${int16Data.length} samples for playback`, 'audio');
            audioQueue.push(int16Data);
            if (!isPlaying) {
                playNextChunk();
            }
        }

        async function playNextChunk() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            // Ensure AudioContext is running (browsers suspend it until user interaction)
            if (audioContext.state === 'suspended') {
                log('Resuming AudioContext...', 'event');
                await audioContext.resume();
            }

            isPlaying = true;
            const int16Data = audioQueue.shift();

            // Convert Int16 to Float32
            const float32Data = new Float32Array(int16Data.length);
            for (let i = 0; i < int16Data.length; i++) {
                float32Data[i] = int16Data[i] / 32768;
            }

            // Create audio buffer at 16kHz (the sample rate of received audio)
            // Note: AudioContext may resample internally if its sample rate differs
            const buffer = audioContext.createBuffer(1, float32Data.length, 16000);
            buffer.getChannelData(0).set(float32Data);

            log(`Playing ${int16Data.length} samples (context: ${audioContext.sampleRate}Hz, state: ${audioContext.state})`, 'audio');

            // Play
            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            source.onended = () => playNextChunk();
            source.start();
        }

        function stop() {
            stopRecording();

            if (ws) {
                // Disable streaming before closing
                if (ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: 'set_streaming', enabled: false }));
                }
                ws.close();
                ws = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(t => t.stop());
                mediaStream = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            audioQueue = [];
            isPlaying = false;

            startBtn.disabled = false;
            endTurnBtn.disabled = true;
            stopBtn.disabled = true;
            modeBadge.style.display = 'none';
            streamingIndicator.style.display = 'none';
            placeholder.style.display = 'block';
            setStatus('Disconnected');
            log('Stopped', 'event');
        }
    </script>
</body>
</html>

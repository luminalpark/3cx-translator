version: '3.8'

services:
  gemini-server:
    build:
      context: ./server
      dockerfile: Dockerfile.gemini
    image: gemini-translation-server:latest
    container_name: gemini-translation

    # No GPU required - Gemini inference runs on Google Cloud

    ports:
      - "8001:8001"

    volumes:
      # Mount credentials file for Vertex AI authentication
      - ./ai-tools-471809-5c89057d4ac6.json:/app/credentials.json:ro
      - ./logs:/app/logs

    environment:
      # Required: Vertex AI Configuration
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT}
      - GOOGLE_CLOUD_LOCATION=${GOOGLE_CLOUD_LOCATION:-europe-west4}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials.json

      # Server configuration
      - SERVER_PORT=8001
      - SERVER_HOST=0.0.0.0

      # Vertex AI Gemini model configuration
      # Available models for Live API:
      # - gemini-2.5-flash-live-preview-04-09 (recommended)
      # - gemini-live-2.5-flash (latest)
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-2.5-flash-live-preview-04-09}

      # Voice configuration
      # Available voices: Aoede, Charon, Fenrir, Kore, Puck
      - GEMINI_VOICE=${GEMINI_VOICE:-Kore}

      # Translation defaults
      - DEFAULT_SOURCE_LANG=${DEFAULT_SOURCE_LANG:-auto}
      - DEFAULT_TARGET_LANG=${DEFAULT_TARGET_LANG:-it}

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-info}

    restart: unless-stopped

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

# Optional: Network configuration for multi-service deployments
# networks:
#   default:
#     name: translation-network
